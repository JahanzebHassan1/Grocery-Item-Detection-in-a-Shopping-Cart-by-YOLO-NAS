{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**ðŸš¨ Before Running the Script Please Make Sure you have selected the Run Time as GPU**"
      ],
      "metadata": {
        "id": "KqYNaFs1zzuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 01: Installing the Packages**"
      ],
      "metadata": {
        "id": "LA9VI44c_Dex"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrOIVb4g-9LV"
      },
      "outputs": [],
      "source": [
        "!pip install super_gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ðŸš¨ Restart the Run Time**"
      ],
      "metadata": {
        "id": "1GFVbqbnzlEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 02: Importing all the required libraries**"
      ],
      "metadata": {
        "id": "8vj6ZhW5_ZiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import Trainer\n",
        "from super_gradients.training import dataloaders\n",
        "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPnhQ5DQ_gTu",
        "outputId": "8ac22a62-8b12-44c5-9d54-3a77469d81fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is logged into /root/sg_logs/console.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-21 10:18:16] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n",
            "[2024-04-21 10:18:32] INFO - utils.py - NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n"
      ],
      "metadata": {
        "id": "aiOenmAUA-2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training.losses import PPYoloELoss\n",
        "from super_gradients.training.metrics import DetectionMetrics_050\n",
        "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
        "\n"
      ],
      "metadata": {
        "id": "Zy94Z08FCC9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import models\n"
      ],
      "metadata": {
        "id": "vI9gsW6MJm9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 03: Setting the checkpoint directory and experiment name | Instantiated the trainer**"
      ],
      "metadata": {
        "id": "2xSiKzfx_t9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "trainer = Trainer(experiment_name='retail_yolonas_run', ckpt_root_dir=CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "caMG2wHQ_huB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 04: Exporting the Dataset from Roboflow into the Google Colab Notebook**"
      ],
      "metadata": {
        "id": "63PxbjJi_4jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"API_KEY\")\n",
        "project = rf.workspace(\"muhammadmoin-y1qrz\").project(\"retail-store-axhqk\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHu6ewi2AABm",
        "outputId": "89cfd013-190b-4bfb-a4eb-450aa3b45583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.27)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.0)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (10.3.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.51.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 05: Load your dataset parameters into a dictionary**"
      ],
      "metadata": {
        "id": "ELYsCvoQANtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll need to load your dataset parameters into a dictionary, specifically defining:\n",
        "\n",
        "- path to the parent directory where your data lives\n",
        "- the child directory names for training, validation, and test (if you have testing set) images and labels\n",
        "- class names"
      ],
      "metadata": {
        "id": "-SUct0GrAUV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_params = {\n",
        "    'data_dir':'/content/Retail-Store-1',\n",
        "    'train_images_dir':'train/images',\n",
        "    'train_labels_dir':'train/labels',\n",
        "    'val_images_dir':'valid/images',\n",
        "    'val_labels_dir':'valid/labels',\n",
        "    'test_images_dir':'test/images',\n",
        "    'test_labels_dir':'test/labels',\n",
        "    'classes': ['Apples', 'Banana', 'Bun', 'Cabbage', 'Cold Drink', 'Dry Fruit', 'Eggs', 'Grapes', 'Green Seeds', 'Milk', 'Oil', 'Pineapple', 'Snacks', 'Vegetables', 'Water Bottle', 'Water Bottle', 'bread', 'carrot', 'cucumber', 'fasol', 'garlic', 'hot pepper', 'onion', 'peas', 'salad', 'tin', 'tomato']\n",
        "}\n"
      ],
      "metadata": {
        "id": "l8caxCpbASNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 06: Pass the values for `dataset_params` into the `dataset_params` argument as shown below.**"
      ],
      "metadata": {
        "id": "hciE-i_lA4zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = coco_detection_yolo_format_train(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['train_images_dir'],\n",
        "        'labels_dir': dataset_params['train_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "val_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['val_images_dir'],\n",
        "        'labels_dir': dataset_params['val_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "test_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['test_images_dir'],\n",
        "        'labels_dir': dataset_params['test_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "AiptliRUAq7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99acd5c-020a-4559-eea4-4d82ee602b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rIndexing dataset annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:00<00:00, 4325.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 07: Inspect the Dataset Defined Earlier**"
      ],
      "metadata": {
        "id": "RlzcTycuBN96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dataset.transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5d34uc6BBxz",
        "outputId": "5102a66d-b826-4f5d-86a4-1203e9dac933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<super_gradients.training.transforms.transforms.DetectionMosaic at 0x784b11549150>,\n",
              " <super_gradients.training.transforms.transforms.DetectionRandomAffine at 0x784b11549210>,\n",
              " <super_gradients.training.transforms.transforms.DetectionMixup at 0x784b11549240>,\n",
              " <super_gradients.training.transforms.transforms.DetectionHSV at 0x784b11549270>,\n",
              " <super_gradients.training.transforms.transforms.DetectionHorizontalFlip at 0x784b11549300>,\n",
              " <super_gradients.training.transforms.transforms.DetectionPaddedRescale at 0x784b11549360>,\n",
              " <super_gradients.training.transforms.transforms.DetectionTargetsFormatTransform at 0x784b115493c0>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dataset.dataset_params['transforms'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmSxlyhMBSsI",
        "outputId": "7fb535f3-d7a5-47a6-e8c3-9280a851cf3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DetectionRandomAffine': {'degrees': 10.0, 'translate': 0.1, 'scales': [0.1, 2], 'shear': 2.0, 'target_size': [640, 640], 'filter_box_candidates': True, 'wh_thr': 2, 'area_thr': 0.1, 'ar_thr': 20}}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dataset.dataset_params['transforms'][1]['DetectionRandomAffine']['degrees'] = 10.42"
      ],
      "metadata": {
        "id": "jB92edn6BYE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 08: Plot a batch of training data with their augmentations applied to see what they look like**"
      ],
      "metadata": {
        "id": "Mxhxz9S3Bc_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dataset.plot()"
      ],
      "metadata": {
        "id": "pMcKP5srBZKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 09: Instantiating the model**"
      ],
      "metadata": {
        "id": "KdteZXfTBqu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You saw how to instantiate the model for inference earlier.\n",
        "\n",
        "Below is how to instantiate the model for finetuning. Note you need to add the `num_classes` argument here.\n",
        "\n",
        "Note, for this tutorial we are using `yolo_nas_s`, but SuperGradients has two other flavors of YOLONAS available to you: `yolo_nas_m` and `yolo_nas_l`."
      ],
      "metadata": {
        "id": "ZHAZf-u-B01b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.get('yolo_nas_s',\n",
        "                   num_classes=len(dataset_params['classes']),\n",
        "                   pretrained_weights=\"coco\"\n",
        "                   )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UanFJaQKBz2B",
        "outputId": "e66c5d4a-9eeb-429c-f328-2057ec6e6dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-21 10:23:48] WARNING - checkpoint_utils.py - :warning: The pre-trained models provided by SuperGradients may have their own licenses or terms and conditions derived from the dataset used for pre-training.\n",
            " It is your responsibility to determine whether you have permission to use the models for your use case.\n",
            " The model you have requested was pre-trained on the coco dataset, published under the following terms: https://cocodataset.org/#termsofuse\n",
            "[2024-04-21 10:23:48] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
            "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
            "By downloading the pre-trained weight files you agree to comply with these terms.\n",
            "Downloading: \"https://sghub.deci.ai/models/yolo_nas_s_coco.pth\" to /root/.cache/torch/hub/checkpoints/yolo_nas_s_coco.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.1M/73.1M [00:01<00:00, 65.0MB/s]\n",
            "[2024-04-21 10:23:50] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 10: ðŸ“Š Define metrics and training parameters**\n"
      ],
      "metadata": {
        "id": "f6kMerfuCKBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to define the training parameters for your training run.\n",
        "\n",
        "Full details about the training parameters can be found [here](https://github.com/Deci-AI/super-gradients/blob/master/src/super_gradients/recipes/training_hyperparams/default_train_params.yaml).\n",
        "\n",
        "\n",
        "### ðŸš¨ There are a few **mandatory** arguments that we must define for training params ðŸš¨\n",
        "\n",
        "- `max_epochs` - Max number of training epochs\n",
        "\n",
        "- `loss` - the loss function you want to use\n",
        "\n",
        "- `optimizer` - Optimizer you will be using\n",
        "\n",
        "- `train_metrics_list` - Metrics to log during training\n",
        "\n",
        "- `valid_metrics_list` - Metrics to log during training\n",
        "\n",
        "- `metric_to_watch` - metric which the model checkpoint will be saved according to\n",
        "\n",
        "We can choose from a variety of `optimizer`'s such as: Adam, AdamW, SGD, Lion, or RMSProps. If you choose to change the defualt parameters of these optimizrs you pass them into `optimizer_params`.\n"
      ],
      "metadata": {
        "id": "vPMB5je6CYn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {\n",
        "    # ENABLING SILENT MODE\n",
        "    'silent_mode': True,\n",
        "    \"average_best_models\":True,\n",
        "    \"warmup_mode\": \"linear_epoch_step\",\n",
        "    \"warmup_initial_lr\": 1e-6,\n",
        "    \"lr_warmup_epochs\": 3,\n",
        "    \"initial_lr\": 5e-4,\n",
        "    \"lr_mode\": \"cosine\",\n",
        "    \"cosine_final_lr_ratio\": 0.1,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
        "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
        "    \"ema\": True,\n",
        "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
        "    # ONLY TRAINING FOR 10 EPOCHS FOR THIS EXAMPLE NOTEBOOK\n",
        "    \"max_epochs\": 15,\n",
        "    \"mixed_precision\": True,\n",
        "    \"loss\": PPYoloELoss(\n",
        "        use_static_assigner=False,\n",
        "        # NOTE: num_classes needs to be defined here\n",
        "        num_classes=len(dataset_params['classes']),\n",
        "        reg_max=16\n",
        "    ),\n",
        "    \"valid_metrics_list\": [\n",
        "        DetectionMetrics_050(\n",
        "            score_thres=0.1,\n",
        "            top_k_predictions=300,\n",
        "            # NOTE: num_classes needs to be defined here\n",
        "            num_cls=len(dataset_params['classes']),\n",
        "            normalize_targets=True,\n",
        "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
        "                score_threshold=0.01,\n",
        "                nms_top_k=1000,\n",
        "                max_predictions=300,\n",
        "                nms_threshold=0.7\n",
        "            )\n",
        "        )\n",
        "    ],\n",
        "    \"metric_to_watch\": 'mAP@0.50'\n",
        "}"
      ],
      "metadata": {
        "id": "xdPgBDSSCTkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 11: Download the Demo Videos**"
      ],
      "metadata": {
        "id": "msdWxrVMDGji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1v4rb6M2aextt6s2i9PUhnh7AY1i081WA&confirm=t\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXPvTT62DG5Z",
        "outputId": "b7eb30bf-051a-4a79-bbe2-7a4016af21cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1v4rb6M2aextt6s2i9PUhnh7AY1i081WA&confirm=t\n",
            "To: /content/Demo10_Retail1.mp4\n",
            " 45% 17.8M/39.6M [00:00<00:00, 55.4MB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"https://drive.google.com/uc?id=128_De5Wsf0Jsd_AG5d8nEtU32UsHlgwU&confirm=t\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLS4Nwt-DG8B",
        "outputId": "8e03bebd-96b3-442b-e159-822fe7b6f6e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 39.6M/39.6M [00:00<00:00, 69.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=128_De5Wsf0Jsd_AG5d8nEtU32UsHlgwU&confirm=t\n",
            "To: /content/Demo10_Retail2.mp4\n",
            " 84% 39.3M/46.7M [00:00<00:00, 129MB/s] "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1i0cJDI-zZNddnnufwWdg7YEYITsprhmi&confirm=t\""
      ],
      "metadata": {
        "id": "FDn4ndKSDG-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329150b2-d27b-41b4-a93f-85f2b6cd5eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 46.7M/46.7M [00:00<00:00, 92.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1i0cJDI-zZNddnnufwWdg7YEYITsprhmi&confirm=t\n",
            "To: /content/Demo10_Retail3.mp4\n",
            " 52% 24.6M/47.3M [00:00<00:00, 73.2MB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 12: ðŸ¦¾ Training the model**\n",
        "\n",
        "You've covered a lot of ground so far:\n",
        "\n",
        "âœ… Instantiated the trainer\n",
        "\n",
        "âœ… Defined your dataset parameters and dataloaders\n",
        "\n",
        "âœ… Instantiated a model\n",
        "\n",
        "âœ… Set up your training parameters\n",
        "\n",
        "### â³ Now, its time to train a model\n",
        "\n",
        "Training a model using a SuperGradients is done using the `trainer`.\n",
        "\n",
        "It's as easy as..."
      ],
      "metadata": {
        "id": "riHN7oz9CugX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(model=model,\n",
        "              training_params=train_params,\n",
        "              train_loader=train_data,\n",
        "              valid_loader=val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_lFrW51BhYo",
        "outputId": "82ec75f6-a81e-4365-e61e-7b093d78aa2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-21 10:24:23] INFO - sg_trainer.py - Starting a new run with `run_id=RUN_20240421_102423_414253`\n",
            "[2024-04-21 10:24:23] INFO - sg_trainer.py - Checkpoints directory: checkpoints/retail_yolonas_run/RUN_20240421_102423_414253\n",
            "[2024-04-21 10:24:23] INFO - sg_trainer.py - Using EMA with params {'decay': 0.9, 'decay_type': 'threshold'}\n",
            "Object name `linear_epoch_step` is now deprecated. Please replace it with `LinearEpochLRWarmup`.\n",
            "initialize_param_groups and update_param_groups usages are deprecated since 3.4.0, will be removed in 3.5.0 and have no effect. \n",
            " Assign different learning rates by passing a mapping of layer name prefixes to lr values through initial_lr training hyperparameter (i.e initial_lr={'backbone': 0.01, 'default':0.1})\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is now moved to checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/console_Apr21_10_24_23.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-21 10:24:29] INFO - sg_trainer_utils.py - TRAINING PARAMETERS:\n",
            "    - Mode:                         Single GPU\n",
            "    - Number of GPUs:               1          (1 available on the machine)\n",
            "    - Full dataset size:            856        (len(train_set))\n",
            "    - Batch size per GPU:           16         (batch_size)\n",
            "    - Batch Accumulate:             1          (batch_accumulate)\n",
            "    - Total batch size:             16         (num_gpus * batch_size)\n",
            "    - Effective Batch size:         16         (num_gpus * batch_size * batch_accumulate)\n",
            "    - Iterations per epoch:         53         (len(train_loader))\n",
            "    - Gradient updates per epoch:   53         (len(train_loader) / batch_accumulate)\n",
            "    - Model: YoloNAS_S  (19.03M parameters, 19.03M optimized)\n",
            "    - Learning Rates and Weight Decays:\n",
            "      - default: (19.03M parameters). LR: 0.0005 (19.03M parameters) WD: 0.0, (42.20K parameters), WD: 0.0001, (18.99M parameters)\n",
            "\n",
            "[2024-04-21 10:25:42] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:25:42] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.0024749767035245895\n",
            "[2024-04-21 10:26:52] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:26:52] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.06916115432977676\n",
            "[2024-04-21 10:28:04] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:28:04] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.07532566040754318\n",
            "[2024-04-21 10:29:14] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:29:14] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.1667691320180893\n",
            "[2024-04-21 10:30:23] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:30:23] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.2097228318452835\n",
            "[2024-04-21 10:31:34] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:31:34] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.28238585591316223\n",
            "[2024-04-21 10:33:32] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:33:32] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.3954980671405792\n",
            "[2024-04-21 10:35:54] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:35:54] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.536445677280426\n",
            "[2024-04-21 10:37:35] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:37:35] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.5550416707992554\n",
            "[2024-04-21 10:38:59] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:38:59] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.6240637898445129\n",
            "[2024-04-21 10:40:15] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:40:15] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.6349911689758301\n",
            "[2024-04-21 10:41:39] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:41:39] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.6591539978981018\n",
            "[2024-04-21 10:42:56] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:42:56] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.6739509701728821\n",
            "[2024-04-21 10:44:17] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/retail_yolonas_run/RUN_20240421_102423_414253/ckpt_best.pth\n",
            "[2024-04-21 10:44:17] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.6920294165611267\n",
            "[2024-04-21 10:44:23] INFO - sg_trainer.py - RUNNING ADDITIONAL TEST ON THE AVERAGED MODEL...\n",
            "Validating epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  1.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 13: ðŸ† Get the best trained model**"
      ],
      "metadata": {
        "id": "VWrhOdu7Mxdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "9TJoph4nRGS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1s1EFscYMsOP67eGM1PKqOFJCeRms1OMf&confirm=t\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4POR6bCZnoX",
        "outputId": "d9944f26-6b06-458c-d42b-a362e566bda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1s1EFscYMsOP67eGM1PKqOFJCeRms1OMf&confirm=t\n",
            "To: /content/ckpt_best.pth\n",
            "100% 257M/257M [00:03<00:00, 69.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = models.get('yolo_nas_s',\n",
        "                        num_classes=len(dataset_params['classes']),\n",
        "                        checkpoint_path=\"/content/ckpt_best.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJQBe5WdDYs-",
        "outputId": "74ad3678-743f-4639-df1c-7e6514dd602a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-21 10:47:29] INFO - checkpoint_utils.py - Successfully loaded model weights from /content/ckpt_best.pth EMA checkpoint.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 14: ðŸ§ Evaluating the best trained model on the test set**"
      ],
      "metadata": {
        "id": "j-qT7GHNNiS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(model=best_model,\n",
        "            test_loader=test_data,\n",
        "            test_metrics_list=DetectionMetrics_050(score_thres=0.1,\n",
        "                                                   top_k_predictions=300,\n",
        "                                                   num_cls=len(dataset_params['classes']),\n",
        "                                                   normalize_targets=True,\n",
        "                                                   post_prediction_callback=PPYoloEPostPredictionCallback(score_threshold=0.01,\n",
        "                                                                                                          nms_top_k=1000,\n",
        "                                                                                                          max_predictions=300,\n",
        "                                                                                                          nms_threshold=0.7)\n",
        "                                                  ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcuZNYAzNgPH",
        "outputId": "4b49020a-8447-425a-8820-fbb05f368184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:04<00:00,  1.69it/s]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'PPYoloELoss/loss_cls': 0.9996284,\n",
              " 'PPYoloELoss/loss_iou': 0.43665195,\n",
              " 'PPYoloELoss/loss_dfl': 0.5868175,\n",
              " 'PPYoloELoss/loss': 2.0230975,\n",
              " 'Precision@0.50': 0.04314478114247322,\n",
              " 'Recall@0.50': 0.8894174695014954,\n",
              " 'mAP@0.50': 0.6469568014144897,\n",
              " 'F1@0.50': 0.08084513992071152,\n",
              " 'Best_score_threshold': 0.4899999797344208}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:04<00:00,  1.80it/s]\rTesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:04<00:00,  1.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 15: ðŸ”® Predicting with the best model**\n",
        "\n"
      ],
      "metadata": {
        "id": "tFtxr3jfNq-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_url = '/content/Retail-Store-1/valid/images/-48_jpg.rf.3ade728bc89b24539438b28bf17c1d87.jpg'\n",
        "best_model.predict(img_url).show()"
      ],
      "metadata": {
        "id": "5CFS5fxGNoJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 16: Testing on Video 1**"
      ],
      "metadata": {
        "id": "AndGR9tmcscm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_video_path = f\"/content/Demo10_Retail1.mp4\"\n",
        "output_video_path = \"detections_output1.mp4\""
      ],
      "metadata": {
        "id": "DNV5L1Z3Nzg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "B8YhhjpROBCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.to(device).predict(input_video_path).save(output_video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2lSX_LuOBFY",
        "outputId": "dda933ad-f18e-4991-9df2-aa8c733b7935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Video:   0%|          | 0/302 [00:00<?, ?it/s][2024-04-21 10:58:35] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
            "Processing Video: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 302/302 [00:26<00:00, 11.60it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Display the Output Video**"
      ],
      "metadata": {
        "id": "vjF4U-gsajOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm '/content/result_compressed.mp4'"
      ],
      "metadata": {
        "id": "XUv3BeouOHBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "\n",
        "# Input video path\n",
        "save_path = '/content/detections_output1.mp4'\n",
        "\n",
        "# Compressed video path\n",
        "compressed_path = \"/content/result_compressed.mp4\"\n",
        "\n",
        "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "Hkc-Jwj-aqzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 17: Testing on Video 2**"
      ],
      "metadata": {
        "id": "9coK1U08c0nM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_video_path = f\"/content/Demo10_Retail2.mp4\"\n",
        "output_video_path = \"detections2.mp4\""
      ],
      "metadata": {
        "id": "EQg3eojHcgQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "WOY2o3G3cgVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.to(device).predict(input_video_path).save(output_video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaEiPXNScgY_",
        "outputId": "76c5825f-4725-4b8c-e3b6-f756e0d7d6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Video:   0%|          | 0/337 [00:00<?, ?it/s][2024-04-21 10:50:38] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
            "Processing Video: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 337/337 [00:31<00:00, 10.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Display the Output Video**"
      ],
      "metadata": {
        "id": "qcraVqkqc4fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm '/content/result_compressed.mp4'"
      ],
      "metadata": {
        "id": "2yhkqTg7cgbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "\n",
        "# Input video path\n",
        "save_path = '/content/detections2.mp4'\n",
        "\n",
        "# Compressed video path\n",
        "compressed_path = \"/content/result_compressed.mp4\"\n",
        "\n",
        "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "Id8Xn-Ugasgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 18: Testing on Video 3**"
      ],
      "metadata": {
        "id": "GplFFc6GbuTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_video_path = f\"/content/Demo10_Retail3.mp4\"\n",
        "output_video_path = \"detections3.mp4\""
      ],
      "metadata": {
        "id": "g_2yGmaU_hYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "fZiFiqueb4Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.to(device).predict(input_video_path).save(output_video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4eZM9fmb65U",
        "outputId": "3a15eb13-8b41-48e9-d94b-7b7ae31207fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Video:   0%|          | 0/339 [00:00<?, ?it/s][2024-04-21 10:55:09] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
            "Processing Video:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 332/339 [00:35<00:00, 12.71it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Display the Output Video**"
      ],
      "metadata": {
        "id": "bZ2-khw8b-Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm '/content/result_compressed.mp4'"
      ],
      "metadata": {
        "id": "PeJ1soPzkh5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00dcbee1-003a-42fe-a6ce-2cec2dc1b2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Video:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 335/339 [00:35<00:00, 15.14it/s]\rProcessing Video: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 339/339 [00:35<00:00, 18.48it/s]\rProcessing Video: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 339/339 [00:35<00:00,  9.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "\n",
        "# Input video path\n",
        "save_path = '/content/detections3.mp4'\n",
        "\n",
        "# Compressed video path\n",
        "compressed_path = \"/content/result_compressed.mp4\"\n",
        "\n",
        "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "T1QfvgoUb-ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RTopCu4lcZAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}